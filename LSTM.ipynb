{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Txah9bcaTlZh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from IPython.display import clear_output\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nm_KEQNaUKcy"
   },
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.read_csv('10_Year_Historical_Scaled.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>EMA 20</th>\n",
       "      <th>EMA 50</th>\n",
       "      <th>MACD Line</th>\n",
       "      <th>MACD Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-10-20</td>\n",
       "      <td>0.505697</td>\n",
       "      <td>0.529674</td>\n",
       "      <td>0.544502</td>\n",
       "      <td>0.607034</td>\n",
       "      <td>0.610477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-10-21</td>\n",
       "      <td>0.557537</td>\n",
       "      <td>0.535072</td>\n",
       "      <td>0.546847</td>\n",
       "      <td>0.639224</td>\n",
       "      <td>0.617646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-10-22</td>\n",
       "      <td>0.541571</td>\n",
       "      <td>0.538294</td>\n",
       "      <td>0.548377</td>\n",
       "      <td>0.654164</td>\n",
       "      <td>0.626708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-10-23</td>\n",
       "      <td>0.569956</td>\n",
       "      <td>0.544164</td>\n",
       "      <td>0.551131</td>\n",
       "      <td>0.682956</td>\n",
       "      <td>0.640369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-10-24</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.552225</td>\n",
       "      <td>0.554972</td>\n",
       "      <td>0.721051</td>\n",
       "      <td>0.659782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221755</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>2024-10-14</td>\n",
       "      <td>0.308423</td>\n",
       "      <td>0.348974</td>\n",
       "      <td>0.407447</td>\n",
       "      <td>0.406825</td>\n",
       "      <td>0.412171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221756</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>2024-10-15</td>\n",
       "      <td>0.307252</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>0.407083</td>\n",
       "      <td>0.411746</td>\n",
       "      <td>0.412160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221757</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>2024-10-16</td>\n",
       "      <td>0.304910</td>\n",
       "      <td>0.349227</td>\n",
       "      <td>0.406615</td>\n",
       "      <td>0.414378</td>\n",
       "      <td>0.412735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221758</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>2024-10-17</td>\n",
       "      <td>0.307252</td>\n",
       "      <td>0.349470</td>\n",
       "      <td>0.406285</td>\n",
       "      <td>0.418152</td>\n",
       "      <td>0.414030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221759</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>2024-10-18</td>\n",
       "      <td>0.310375</td>\n",
       "      <td>0.350031</td>\n",
       "      <td>0.406126</td>\n",
       "      <td>0.423270</td>\n",
       "      <td>0.416200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3221760 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ticker        Date  Adj Close    EMA 20    EMA 50  MACD Line  \\\n",
       "0          AAL  2014-10-20   0.505697  0.529674  0.544502   0.607034   \n",
       "1          AAL  2014-10-21   0.557537  0.535072  0.546847   0.639224   \n",
       "2          AAL  2014-10-22   0.541571  0.538294  0.548377   0.654164   \n",
       "3          AAL  2014-10-23   0.569956  0.544164  0.551131   0.682956   \n",
       "4          AAL  2014-10-24   0.596369  0.552225  0.554972   0.721051   \n",
       "...        ...         ...        ...       ...       ...        ...   \n",
       "3221755   ZYXI  2024-10-14   0.308423  0.348974  0.407447   0.406825   \n",
       "3221756   ZYXI  2024-10-15   0.307252  0.349241  0.407083   0.411746   \n",
       "3221757   ZYXI  2024-10-16   0.304910  0.349227  0.406615   0.414378   \n",
       "3221758   ZYXI  2024-10-17   0.307252  0.349470  0.406285   0.418152   \n",
       "3221759   ZYXI  2024-10-18   0.310375  0.350031  0.406126   0.423270   \n",
       "\n",
       "         MACD Signal  \n",
       "0           0.610477  \n",
       "1           0.617646  \n",
       "2           0.626708  \n",
       "3           0.640369  \n",
       "4           0.659782  \n",
       "...              ...  \n",
       "3221755     0.412171  \n",
       "3221756     0.412160  \n",
       "3221757     0.412735  \n",
       "3221758     0.414030  \n",
       "3221759     0.416200  \n",
       "\n",
       "[3221760 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation and Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kMjQtG30TvB0"
   },
   "outputs": [],
   "source": [
    "def create_dataset(data, lookback, prediction_horizon):\n",
    "    n_samples = len(data) - lookback - prediction_horizon\n",
    "    if n_samples <= 0:\n",
    "        return np.empty((0, lookback, data.shape[1] - 1)), np.empty((0, prediction_horizon))\n",
    "\n",
    "    X = np.empty((n_samples, lookback, data.shape[1] - 1), dtype=np.float32)\n",
    "    Y = np.empty((n_samples, prediction_horizon), dtype=np.float32)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        X[i] = data[i:(i + lookback), 1:]\n",
    "        Y[i] = data[(i + lookback):(i + lookback + prediction_horizon), 0]\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDa_ivTeT_hZ",
    "outputId": "497abf8d-8429-47c7-8a39-597092079355"
   },
   "outputs": [],
   "source": [
    "def process_stock_data(df, lookback, prediction_horizon):\n",
    "    tickers = df['Ticker'].unique()\n",
    "    train_x_list, train_y_list, test_x_list, test_y_list = [], [], [], []\n",
    "\n",
    "    total_train_samples, total_test_samples = 0, 0\n",
    "\n",
    "    for ticker in tickers:\n",
    "        stock_data = df[df['Ticker'] == ticker].copy()\n",
    "        stock_data.drop(columns=['Ticker', 'Date'], inplace=True)\n",
    "\n",
    "        train_split_len = int(len(stock_data) * 0.8)\n",
    "        train_data = stock_data.values[:train_split_len]\n",
    "        test_data = stock_data.values[train_split_len:]\n",
    "\n",
    "        usable_train_samples = len(train_data) - lookback - prediction_horizon\n",
    "        usable_test_samples = len(test_data) - lookback - prediction_horizon\n",
    "\n",
    "        print(f\"Ticker: {ticker}, Train rows: {len(train_data)}, Test rows: {len(test_data)}\")\n",
    "        print(f\"Ticker: {ticker}, Usable train samples: {usable_train_samples}, Usable test samples: {usable_test_samples}\")\n",
    "\n",
    "        train_x, train_y = create_dataset(train_data, lookback, prediction_horizon)\n",
    "        test_x, test_y = create_dataset(test_data, lookback, prediction_horizon)\n",
    "\n",
    "        total_train_samples += train_x.shape[0]\n",
    "        total_test_samples += test_x.shape[0]\n",
    "\n",
    "        train_x_list.append(train_x)\n",
    "        train_y_list.append(train_y)\n",
    "        test_x_list.append(test_x)\n",
    "        test_y_list.append(test_y)\n",
    "\n",
    "        del train_data, test_data\n",
    "        gc.collect()\n",
    "\n",
    "    train_x = np.concatenate(train_x_list, axis=0)\n",
    "    train_y = np.concatenate(train_y_list, axis=0)\n",
    "    test_x = np.concatenate(test_x_list, axis=0)\n",
    "    test_y = np.concatenate(test_y_list, axis=0)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Total train samples: {total_train_samples}, Total test samples: {total_test_samples}\")\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDa_ivTeT_hZ",
    "outputId": "497abf8d-8429-47c7-8a39-597092079355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples: 2490880, Total test samples: 559360\n",
      "Training data shape: X=(2490880, 60, 4), Y=(2490880, 7)\n",
      "Testing data shape: X=(559360, 60, 4), Y=(559360, 7)\n"
     ]
    }
   ],
   "source": [
    "lookback = 60\n",
    "prediction_horizon = 7\n",
    "\n",
    "train_x, train_y, test_x, test_y = process_stock_data(scaled_df, lookback, prediction_horizon)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Training data shape: X={train_x.shape}, Y={train_y.shape}\")\n",
    "print(f\"Testing data shape: X={test_x.shape}, Y={test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDa_ivTeT_hZ",
    "outputId": "497abf8d-8429-47c7-8a39-597092079355"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Device being used: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=32):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, prediction_horizon)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tensor = torch.FloatTensor(train_x).to(device)\n",
    "train_y_tensor = torch.FloatTensor(train_y).to(device)\n",
    "test_x_tensor = torch.FloatTensor(test_x).to(device)\n",
    "test_y_tensor = torch.FloatTensor(test_y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_x.shape[2]\n",
    "model = LSTMModel(input_size=input_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWD1udTdW-hC",
    "outputId": "7e2af872-c3a2-46da-b21d-8f285a875de2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 77840/77840 [04:34<00:00, 283.68batch/s, loss=0.000394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Avg Loss: 0.0023, Time Elapsed: 274.39s, Estimated Time Left: 1097.57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 77840/77840 [04:34<00:00, 283.95batch/s, loss=0.000418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Avg Loss: 0.0018, Time Elapsed: 548.53s, Estimated Time Left: 822.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 77840/77840 [04:35<00:00, 282.79batch/s, loss=0.000423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Avg Loss: 0.0017, Time Elapsed: 823.79s, Estimated Time Left: 549.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 77840/77840 [04:35<00:00, 282.73batch/s, loss=0.000417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Avg Loss: 0.0016, Time Elapsed: 1099.11s, Estimated Time Left: 274.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 77840/77840 [04:34<00:00, 283.56batch/s, loss=0.000422]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Avg Loss: 0.0016, Time Elapsed: 1373.62s, Estimated Time Left: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = len(train_x_tensor) // batch_size\n",
    "\n",
    "    with tqdm(total=num_batches, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for i in range(0, len(train_x_tensor), batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            x_batch = train_x_tensor[i:i + batch_size]\n",
    "            y_batch = train_y_tensor[i:i + batch_size]\n",
    "\n",
    "            y_pred = model(x_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / num_batches\n",
    "    elapsed_time = time.time() - start_time\n",
    "    time_left = (elapsed_time / (epoch + 1)) * (num_epochs - (epoch + 1))\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Avg Loss: {avg_epoch_loss:.4f}, Time Elapsed: {elapsed_time:.2f}s, Estimated Time Left: {time_left:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'LSTM.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1584/4194769303.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('LSTM.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('LSTM.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batched_predictions(model, test_x_tensor, batch_size):\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_x_tensor), batch_size):\n",
    "            x_batch = test_x_tensor[i:i + batch_size]\n",
    "            batch_predictions = model(x_batch)\n",
    "            predictions.append(batch_predictions.cpu().numpy())\n",
    "            torch.cuda.empty_cache()\n",
    "    return np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = get_batched_predictions(model, test_x_tensor, batch_size)\n",
    "\n",
    "test_y_true = test_y_tensor.cpu().numpy()\n",
    "\n",
    "if len(test_predictions.shape) > 1 and test_predictions.shape[1] > 1:\n",
    "    test_predictions = test_predictions[:, 0]\n",
    "    test_y_true = test_y_true[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(test_y_true, test_predictions)\n",
    "mae = mean_absolute_error(test_y_true, test_predictions)\n",
    "rmse = root_mean_squared_error(test_y_true, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics\n",
      "Mean Squared Error (MSE): 0.0013\n",
      "Mean Absolute Error (MAE): 0.0263\n",
      "Root Mean-Squared Error (RMSE): 0.04\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation Metrics\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean-Squared Error (RMSE): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
